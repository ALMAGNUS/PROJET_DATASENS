{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c06424cb",
   "metadata": {},
   "source": [
    "# DataSens — E1 (v1) — 05_snapshot_and_readme\n\n**Objectif :**\n\n- Prouver E1 : base créée, remplie, requêtable.\n- Produire un **snapshot \"audit\"** :\n  - Exports CSV (ou parquet plus tard)\n  - Stats par table\n  - Mini README auto (copiable dans Notion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dbc485",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\nfrom sqlmodel import Session, select, create_engine, SQLModel, Field\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import Optional\n\n# Schema classes (copie-colle)\nclass Source(SQLModel, table=True):\n    __tablename__ = \"source\"\n    source_id: Optional[int] = Field(default=None, primary_key=True)\n    name: str\n    source_kind: str\n    url: Optional[str] = None\n    frequency: Optional[str] = None\n    active: bool = True\n\nclass RawData(SQLModel, table=True):\n    __tablename__ = \"raw_data\"\n    raw_id: Optional[int] = Field(default=None, primary_key=True)\n    source_id: int = Field(foreign_key=\"source.source_id\", index=True)\n    title: Optional[str] = None\n    text: str\n    author: Optional[str] = None\n    created_at: datetime = Field(default_factory=datetime.utcnow, index=True)\n\nclass SyncLog(SQLModel, table=True):\n    __tablename__ = \"sync_log\"\n    log_id: Optional[int] = Field(default=None, primary_key=True)\n    source_id: int = Field(foreign_key=\"source.source_id\", index=True)\n    sync_at: datetime = Field(default_factory=datetime.utcnow, index=True)\n    status: str\n    records_inserted: int = 0\n    message: Optional[str] = None\n\nclass Topic(SQLModel, table=True):\n    __tablename__ = \"topic\"\n    topic_id: Optional[int] = Field(default=None, primary_key=True)\n    name: str = Field(index=True, unique=True)\n    category: Optional[str] = None\n\nclass DocumentTopic(SQLModel, table=True):\n    __tablename__ = \"document_topic\"\n    raw_id: int = Field(foreign_key=\"raw_data.raw_id\", primary_key=True)\n    topic_id: int = Field(foreign_key=\"topic.topic_id\", primary_key=True)\n\nclass ModelOutput(SQLModel, table=True):\n    __tablename__ = \"model_output\"\n    output_id: Optional[int] = Field(default=None, primary_key=True)\n    raw_id: int = Field(foreign_key=\"raw_data.raw_id\", index=True)\n    model_name: str\n    label: str\n    confidence: float = Field(ge=0.0, le=1.0)\n    created_at: datetime = Field(default_factory=datetime.utcnow, index=True)\n\nBASE_DIR = Path.home() / \"datasens_project\"\nEXPORT_DIR = BASE_DIR / \"exports\" / \"E1_v1\"\nEXPORT_DIR.mkdir(parents=True, exist_ok=True)\n\nDB_PATH = BASE_DIR / \"datasens_e1_v1.sqlite\"\nDATABASE_URL = f\"sqlite:///{DB_PATH}\"\nengine = create_engine(DATABASE_URL, echo=False)\n\ntables_dict = {\n    \"source\": Source,\n    \"raw_data\": RawData,\n    \"sync_log\": SyncLog,\n    \"topic\": Topic,\n    \"document_topic\": DocumentTopic,\n    \"model_output\": ModelOutput,\n}\n\nprint(f\" Setup complete: {EXPORT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef8487b",
   "metadata": {},
   "source": [
    "## 1) Export CSV (snapshot complet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9034c1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Session(engine) as session:\n    for table_name, model_class in tables_dict.items():\n        rows = session.exec(select(model_class)).all()\n        df = pd.DataFrame([r.model_dump() for r in rows])\n        \n        output_file = EXPORT_DIR / f\"{table_name}.csv\"\n        df.to_csv(output_file, index=False)\n        print(f\" Exported {table_name}: {len(rows)} rows → {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a0081f",
   "metadata": {},
   "source": [
    "## 2) Statistiques d'audit (preuves E1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cc12a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Session(engine) as session:\n    stats = {name: len(session.exec(select(model_class)).all()) for name, model_class in tables_dict.items()}\n\nprint(\"\\n\" + \"=\"*50)\nprint(\" AUDIT STATS — E1 V1 SUCCESS\")\nprint(\"=\"*50)\nfor table, count in sorted(stats.items()):\n    status = \"\" if count > 0 else \"\"\n    print(f\"{status} {table:20s}: {count:4d} rows\")\nprint(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2bcf0b",
   "metadata": {},
   "source": [
    "## 3) README Auto (copiable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683190e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "readme = f\"\"\"\n# DataSens — E1 V1 — Complete Setup\n\n## Database\n- **File**: {DB_PATH}\n- **Engine**: SQLite (zero-config)\n- **Tables**: source, raw_data, sync_log, topic, document_topic, model_output\n\n## Audit Trail\n- **Setup**: 01_setup_env.ipynb\n- **Schema**: 02_schema_create.ipynb\n- **Ingestion**: 03_ingest_sources.ipynb\n- **CRUD**: 04_crud_tests.ipynb\n- **Snapshot**: 05_snapshot_and_readme.ipynb\n\n## Data Stats\n\"\"\"\n\nwith Session(engine) as session:\n    for table, count in sorted(stats.items()):\n        readme += f\"- **{table}**: {count} rows\\n\"\n\nreadme += f\"\"\"\n## Exports\n- Location: {EXPORT_DIR}\n- Format: CSV (one file per table)\n- Use case: Audit, backup, external tools\n\n## Git Tags\n- E1_v1_step01_setup_env_ok\n- E1_v1_step02_schema_ok\n- E1_v1_step03_ingest_ok\n- E1_v1_step04_crud_ok\n- E1_v1_step05_snapshot_ok\n\n## Next Steps (E1 V2)\n1. Real data sources (RSS multi-source, GDELT, API)\n2. PostgreSQL migration\n3. Data lake with Hive partitioning\n4. PySpark ETL\n\"\"\"\n\nprint(readme)\n\n# Save README\nreadme_file = EXPORT_DIR / \"E1_V1_README.md\"\nwith open(readme_file, \"w\") as f:\n    f.write(readme)\nprint(f\"\\n README saved: {readme_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a465d8",
   "metadata": {},
   "source": [
    "##  Final Commit & Tag\n\n**Congratulations!**  E1 V1 complete.\n\n```bash\ngit add .\ngit commit -m \"E1 v1 - complete (schema + data + CRUD + audit)\"\ngit tag E1_v1_step05_snapshot_ok\ngit tag E1_v1_complete\n```\n\n### What You've Built\n1.  **Database schema** (SQLite, 6 tables, 3NF)\n2.  **Data ingestion** (RSS, topics, tagging)\n3.  **CRUD operations** (full test suite)\n4.  **Audit trail** (sync_log, version tags)\n5.  **Exports** (CSV snapshots)\n\n### Ready for E1 V2\n- Real multi-source ingestion\n- PostgreSQL + DataLake\n- Production-grade error handling\n\n---\n\n**Status**:  **E1 V1 Ready for Jury Presentation**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}