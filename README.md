# ğŸ“Š DataSens E1 â€” Data Extraction & Transformation Pipeline

![Status](https://img.shields.io/badge/Status-Production%20Ready-brightgreen?style=flat-square)
![Python](https://img.shields.io/badge/Python-3.10+-blue?style=flat-square)
![License](https://img.shields.io/badge/License-MIT-blue?style=flat-square)
![E1 Complete](https://img.shields.io/badge/E1-v1.0.0%20Complete-green?style=flat-square)

---

```text
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                              â•‘
â•‘     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—     â•‘
â•‘     â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•— â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•     â•‘
â•‘     â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—     â•‘
â•‘     â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â•šâ•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â•šâ•â•â•â•â–ˆâ–ˆâ•‘     â•‘
â•‘     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘     â•‘
â•‘     â•šâ•â•â•â•â•â•  â•šâ•â•  â•šâ•â•   â•šâ•â•   â•šâ•â•  â•šâ•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•â•â•šâ•â•â•â•â•â•â•     â•‘
â•‘                                                                              â•‘
â•‘                   â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—                     â•‘
â•‘                   â•‘  ---------- README -----------     â•‘                     â•‘
â•‘                   â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                     â•‘
â•‘                                                                              â•‘
â•‘                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

## ğŸ¯ Overview

**DATASENS E1** is a professional data extraction, transformation, and export pipeline that:

- **Extracts** from **10 heterogeneous sources** (RSS, APIs, web scraping)
- **Cleans & standardizes** with quality scoring and deduplication  
- **Exports** to three data zones (RAW â†’ SILVER â†’ GOLD)
- **Produces** production-ready parquet files for E2/E3 ML pipelines

**216 articles | 0 corruption | Zero duplicates | 100% clean**

---

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

**Core Dependencies:**
- `pandas==2.3.3` â€” Data processing
- `pyarrow==22.0.0` â€” Parquet engine
- `kagglehub==0.2.5` â€” Kaggle datasets API
- `feedparser` â€” RSS extraction
- `requests`, `beautifulsoup4` â€” HTTP & web scraping
- `sqlalchemy` â€” Database ORM

### 2. Initialize Database

```bash
python scripts/setup_with_sql.py
```

Creates SQLite database with:
- 7 tables (source, raw_data, sync_log, topic, document_topic, model_output)
- 10 sources configured
- Proper indexes for performance

### 3. Run E1 Pipeline

```bash
python main.py
```

**Output:**
- 216 articles extracted to database
- sync_log updated (10 sources logged)
- Ready for export

### 4. Export Data (RAW â†’ SILVER â†’ GOLD)

```bash
python e1_export_correct.py
```

**Produces:**
- ğŸ”´ `data/raw/sources_2025-12-16/` (JSON + CSV)
- ğŸŸ¡ `data/silver/v_2025-12-16/` (Parquet)
- ğŸŸ¢ `data/gold/date=2025-12-16/` (PySpark parquet)

---

## ğŸ“ Three-Zone Architecture

```
ğŸ”´ RAW ZONE (Native Formats - NO Processing)
   data/raw/sources_2025-12-16/
   â”œâ”€ raw_articles.json (137.4 KB) â† Direct from extractors
   â””â”€ raw_articles.csv  (100.4 KB)  â† No transformations

ğŸŸ¡ SILVER ZONE (Cleaned & Standardized)
   data/silver/v_2025-12-16/
   â””â”€ silver_articles.parquet (64.5 KB)
      â€¢ Deduplicated (fingerprint-based)
      â€¢ Quality scores (0-1 scale)
      â€¢ Topic tagging (8 topics, multiple per article)
      â€¢ Text cleaning indicators

ğŸŸ¢ GOLD ZONE (ML-Enriched, PySpark Ready)
   data/gold/date=2025-12-16/
   â””â”€ articles.parquet (67.9 KB)
      â€¢ Sentiment analysis (176 neutral, 32 positive, 8 negative)
      â€¢ Confidence scores (0-1)
      â€¢ Processing metadata
      â€¢ Partitioned for PySpark
```

---

## ğŸ“š Core Files

| File | Purpose | Status |
|------|---------|--------|
| **main.py** | E1 pipeline orchestration | âœ… |
| **setup_with_sql.py** | Database initialization | âœ… |
| **e1_export_correct.py** | RAW â†’ SILVER â†’ GOLD | âœ… |
| **src/core.py** | All extractors + transformers | âœ… |
| **sources_config.json** | 10 sources configuration | âœ… |
| **requirements.txt** | All dependencies | âœ… |

---

## ğŸ”— Data Sources (14 sources actives)

### Sources Actives (14 sources)

> **Note**: Les statistiques ci-dessous sont une **photo au 2025-12-20**. La collecte Ã©volue quotidiennement pour les sources dynamiques. Les nombres d'articles augmentent Ã  chaque exÃ©cution du pipeline.

| # | Source | Type | Records (20/12/2025) | Status |
|---|--------|------|---------------------|--------|
| 1 | kaggle_french_opinions | Dataset | 38,327 | âœ“ Fondation |
| 2 | google_news_rss | RSS | 1,456 | âœ“ Dynamique |
| 3 | zzdb_csv | CSV | 930 | âœ“ Fondation |
| 4 | trustpilot_reviews | Scraping | 658 | âœ“ Dynamique |
| 5 | yahoo_finance | RSS | 624 | âœ“ Dynamique |
| 6 | reddit_france | API | 377 | âœ“ Dynamique |
| 7 | rss_french_news | RSS | 259 | âœ“ Dynamique |
| 8 | openweather_api | API | 187 | âœ“ Dynamique |
| 9 | gdelt_events | BigData | 79 | âœ“ Fondation |
| 10 | datagouv_datasets | Dataset | 50 | âœ“ Dynamique |
| 11 | ifop_barometers | Scraping | 18 | âœ“ Dynamique |
| 12 | insee_indicators | API | 5 | âœ“ Dynamique |
| 13 | GDELT_Last15_English | BigData | 2 | âœ“ Dynamique |
| 14 | GDELT_Master_List | BigData | 0 | âœ“ Dynamique |

**Total articles en base** (au 20/12/2025): **43,022 articles**

**Classification**:
- **Fondation** (statiques, intÃ©grÃ©es une fois) : `kaggle_french_opinions`, `gdelt_events`, `zzdb_csv`
  - Ces sources sont figÃ©es aprÃ¨s leur premiÃ¨re intÃ©gration et ne sont plus collectÃ©es
- **Dynamiques** (collecte quotidienne) : Toutes les autres sources actives
  - Les sources dynamiques collectent de nouveaux articles Ã  chaque exÃ©cution du pipeline
  - Les nombres d'articles augmentent quotidiennement pour ces sources

### Sources Inactives (pour rÃ©fÃ©rence)

| Source | Type | Status |
|--------|------|--------|
| Kaggle_StopWords_28Lang | Dataset | Inactif |
| Kaggle_StopWords | Dataset | Inactif |
| Kaggle_FrenchFinNews | Dataset | Inactif |
| Kaggle_SentimentLexicons | Dataset | Inactif |
| Kaggle_InsuranceReviews | Dataset | Inactif |
| Kaggle_FrenchTweets | Dataset | Inactif |
| zzdb_synthetic | SQLite | Inactif |

---

## ğŸ“Š Dashboard de Visualisation

### âœ… Automatique et Dynamique

Le systÃ¨me inclut **3 outils de visualisation** qui se mettent Ã  jour automatiquement :

1. **Rapport de Collecte** : S'affiche automatiquement aprÃ¨s chaque `python main.py`
2. **Dashboard Global** : Vue d'ensemble complÃ¨te avec `python show_dashboard.py`
3. **Visualiseur CSV** : Explorer les fichiers exports/ avec `python view_exports.py`

### ğŸ“‹ Rapport de Collecte (Session Actuelle)

Le rapport s'affiche **automatiquement** aprÃ¨s chaque collecte et montre :
- Articles collectÃ©s, taggÃ©s, analysÃ©s dans cette session
- DÃ©tail par source des nouveaux articles
- Distribution topics et sentiment des nouveaux articles

### ğŸ“Š Dashboard Global

```bash
# Afficher le dashboard complet (toujours Ã  jour)
python scripts/show_dashboard.py
```

Affiche :
- **RÃ©sumÃ© global** : Total articles, uniques, nouveaux aujourd'hui, enrichis
- **Nouveaux articles** : DÃ©tail par source des articles collectÃ©s aujourd'hui
- **Enrichissement Topics** : Articles taggÃ©s, topics utilisÃ©s, confiance moyenne
- **Enrichissement Sentiment** : Distribution positif/neutre/nÃ©gatif
- **Articles par source** : Statistiques dÃ©taillÃ©es par source
- **Ã‰valuation IA** : Status du dataset pour l'entraÃ®nement IA

### ğŸ‘€ Visualiser les CSV dans exports/

```bash
# Script interactif pour explorer les CSV
python scripts/view_exports.py
```

Les fichiers CSV sont aussi directement accessibles dans `exports/` :
- **`raw.csv`** : DonnÃ©es brutes (DB + fichiers locaux)
- **`silver.csv`** : DonnÃ©es nettoyÃ©es avec topics
- **`gold.csv`** : DonnÃ©es complÃ¨tes avec topics + sentiment

Vous pouvez les ouvrir directement dans Excel, Notepad, ou les importer dans Power BI.

### ğŸ”„ Enrichir rÃ©troactivement tous les articles

```bash
# Enrichir tous les articles existants (topics + sentiment)
python scripts/enrich_all_articles.py
```

ğŸ“– **Guide complet** : Voir `docs/DASHBOARD_GUIDE.md` pour plus de dÃ©tails

## ğŸ“Š Data Quality Verification

### Pipeline Summary âœ“

- **Total Articles Extracted**: 81
- **Articles Cleaned**: 81
- **Articles Loaded to DB**: 10 (new today)
- **Total in DB**: 1017 (consolidated across runs)
- **Deduplication Rate**: 87.7%
- **Quality Score**: 100%

### Export Outputs âœ“

| File | Records | Size | Format |
|------|---------|------|--------|
| raw.csv | 1017 | 0.73 MB | CSV (raw data + Kaggle) |
| silver.csv | 1017 | 0.17 MB | CSV (classified by DOCUMENT_TOPIC) |
| gold.csv | 9 | 1 KB | CSV (aggregated by source) |
| gold.parquet | 9 | 10 KB | Parquet (for Power BI) |

### Transformations Applied âœ“

| Transformation | Coverage | Status |
|---|---|---|
| Deduplication | 71/81 | âœ“ |
| Quality Scoring | 1017/1017 | âœ“ |
| Topic Classification | 1017/1017 (8 topics) | âœ“ |
| Sentiment Analysis | 9 sources (MODEL_OUTPUT) | âœ“ |
| Partitioned Raw Data | sources_2025-12-17 | âœ“ |

---

## ğŸ—ï¸ Database Schema

### 7 Core Tables

1. **source** â€” 10 configured sources
2. **raw_data** â€” 216 articles (direct from extractors)
3. **sync_log** â€” 20 logs (2 runs Ã— 10 sources)
4. **topic** â€” 8 predefined topics
5. **document_topic** â€” 207 article-topic mappings
6. **model_output** â€” 648 ML predictions
7. **sqlite_sequence** â€” Auto-increment counters

---

## ğŸ“ˆ Statistics

| Metric | Value |
|--------|-------|
| Total Articles | 216 |
| Active Sources | 10/10 |
| Topics Created | 8 |
| Duplicates Removed | 0 |
| Data Corruption | 0 |
| Quality Score Range | 0.01 - 0.99 |
| Model Outputs | 648 |
| Transformations | 100% complete |

---

## âœ… Production Readiness

âœ… **Code Quality**
- Ruff linting: 100% pass
- Type hints throughout
- OOP architecture (SOLID principles)
- No hardcoded values

âœ… **Data Quality**
- Zero duplicates
- Zero corruption
- 100% article coverage
- Proper deduplication

âœ… **Documentation**
- README (this file)
- AGILE_ROADMAP.md (43 user stories)
- SCHEMA_DESIGN.md (database design)
- CHANGELOG.md (version history)

âœ… **Dependencies**
- All listed in requirements.txt
- Pinned versions
- pandas, pyarrow, fastparquet installed

---

## ğŸ“ File Structure

```
PROJET_DATASENS/
â”œâ”€â”€ main.py                          # E1 orchestration (utilise E1 isolÃ©)
â”œâ”€â”€ setup_with_sql.py                # Database setup
â”œâ”€â”€ requirements.txt                 # Dependencies
â”œâ”€â”€ sources_config.json              # Sources config
â”œâ”€â”€ README.md                        # This file
â”œâ”€â”€ pytest.ini                       # Configuration pytest
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ e1/                          # E1 ISOLÃ‰ (package privÃ©)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ core.py                  # Extracteurs et transformers
â”‚   â”‚   â”œâ”€â”€ repository.py            # Repository pattern
â”‚   â”‚   â”œâ”€â”€ tagger.py                # Topic tagger
â”‚   â”‚   â”œâ”€â”€ analyzer.py             # Sentiment analyzer
â”‚   â”‚   â”œâ”€â”€ aggregator.py            # Data aggregator
â”‚   â”‚   â”œâ”€â”€ exporter.py             # Gold exporter
â”‚   â”‚   â””â”€â”€ pipeline.py             # E1Pipeline isolÃ©
â”‚   â”œâ”€â”€ e2/                          # E2 (FastAPI + RBAC) - PRÃŠT
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ e3/                          # E3 (PySpark + ML) - PRÃŠT
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ shared/                      # INTERFACES (contrats E1 â†” E2/E3)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ interfaces.py           # E1DataReader (lecture seule)
â”‚   â”œâ”€â”€ dashboard.py                 # Dashboard utilitaires
â”‚   â”œâ”€â”€ collection_report.py         # Rapport de collecte
â”‚   â””â”€â”€ metrics.py                   # Prometheus metrics
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_e1_isolation.py         # Tests non-rÃ©gression E1
â”‚   â””â”€â”€ README_E1_ISOLATION.md       # Guide tests
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ PLAN_ACTION_E1_E2_E3.md      # Plan d'action dÃ©taillÃ©
â”‚   â”œâ”€â”€ E1_ISOLATION_STRATEGY.md    # StratÃ©gie isolation
â”‚   â”œâ”€â”€ E1_ISOLATION_COMPLETE.md    # RÃ©capitulatif Phase 0
â”‚   â””â”€â”€ ROADMAP_EVOLUTION.md         # Roadmap E1 â†’ E2 â†’ E3
â””â”€â”€ data/
    â”œâ”€â”€ raw/
    â”‚   â””â”€â”€ sources_2025-12-20/
    â”‚       â”œâ”€â”€ raw_articles.json
    â”‚       â””â”€â”€ raw_articles.csv
    â”œâ”€â”€ silver/
    â”‚   â””â”€â”€ v_2025-12-20/
    â”‚       â””â”€â”€ silver_articles.parquet
    â””â”€â”€ gold/
        â””â”€â”€ date=2025-12-20/
            â””â”€â”€ articles.parquet
```

---

## ğŸ“ Key Concepts

### Three-Zone Architecture

- **RAW**: Unprocessed data directly from sources (JSON/CSV)
- **SILVER**: Cleaned, standardized, deduplicated (Parquet)
- **GOLD**: ML-enriched, production-ready (PySpark Parquet)

### Immutable Data Pipeline

1. No modifications to raw data (source of truth)
2. All transformations tracked
3. Lineage clearly documented
4. Easy to reprocess if needed

### PySpark Ready

- GOLD zone uses `date=2025-12-16/` partitioning
- Compatible with PySpark's partitioned dataset format
- Can be read with: `spark.read.parquet("data/gold/")`

---

## ğŸ”’ E1 Isolation (Phase 0 - Complete)

**E1 est maintenant isolÃ© et protÃ©gÃ©** pour la construction de E2/E3.

### Structure IsolÃ©e
- âœ… Package `src/e1/` : E1 complÃ¨tement isolÃ©
- âœ… Interface `src/shared/interfaces.py` : E1DataReader (lecture seule)
- âœ… Tests de non-rÃ©gression : `tests/test_e1_isolation.py`
- âœ… Documentation : `docs/E1_ISOLATION_STRATEGY.md`

### RÃ¨gles d'Isolation
- âœ… E2/E3 utilisent UNIQUEMENT `E1DataReader` (pas de modification E1)
- âœ… Tests E1 passent Ã  100% avant chaque merge E2/E3
- âœ… Aucune modification `src/e1/` depuis E2/E3

**Voir** : `docs/E1_ISOLATION_COMPLETE.md` pour dÃ©tails complets

---

## ğŸš€ Next Steps (E2/E3)

This E1 pipeline feeds into:

**Phase 1 â€” Docker & CI/CD**
- Containerisation E1
- Tests automatisÃ©s
- CI/CD workflows

**Phase 2 â€” FastAPI + RBAC**
- API REST sÃ©curisÃ©e
- Authentification JWT
- ContrÃ´le d'accÃ¨s par zone (RAW/SILVER/GOLD)

**Phase 3 â€” PySpark**
- Traitement Big Data
- IntÃ©gration avec FastAPI

**Phase 4 â€” ML Fine-tuning**
- Fine-tuning FlauBERT (sentiment)
- Fine-tuning CamemBERT (topics)

**Phase 5 â€” Streamlit Dashboard**
- Visualisations interactives
- PrÃ©dictions IA

**Phase 6 â€” Mistral IA**
- Insights gÃ©nÃ©rÃ©s par IA
- Climat social/financier

**Voir** : `docs/PLAN_ACTION_E1_E2_E3.md` pour plan dÃ©taillÃ©

---

## ğŸ“„ License

MIT License â€” See LICENSE.md

---

## ğŸ¤ Contributing

Contributions welcome! See [CONTRIBUTING.md](CONTRIBUTING.md)

---

**Last Updated:** December 16, 2025  
**Status:** âœ… Production Ready  
**E1 Complete:** âœ… All components delivered
